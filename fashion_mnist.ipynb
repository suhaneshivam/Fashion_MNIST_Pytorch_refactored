{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d60b2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from IPython.display import display, clear_output\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "\n",
    "from itertools import product\n",
    "from collections import namedtuple\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1f54065",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunManager():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.epoch_count = 0\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        self.epoch_start_time = None\n",
    "        \n",
    "        self.run_params = None\n",
    "        self.run_count = 0\n",
    "        self.run_data = []\n",
    "        self.run_start_time = 0\n",
    "        \n",
    "        self.network = None\n",
    "        self.loader = None \n",
    "        self.tb = None\n",
    "    \n",
    "    def begin_run(self ,run ,network ,loader):\n",
    "        \n",
    "        self.run_start_time = time.time()\n",
    "        \n",
    "        self.run_params = run\n",
    "        self.run_count += 1\n",
    "        self.network = network\n",
    "        self.loader = loader\n",
    "        self.tb = SummaryWriter(comment = f'-{run}')\n",
    "        \n",
    "        images ,labels = next(iter(self.loader))\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "        \n",
    "        self.tb.add_image('images' ,grid)\n",
    "        self.tb.add_graph(self.network ,images)\n",
    "        \n",
    "    def end_run(self):\n",
    "        self.tb.close()\n",
    "        self.epoch_count = 0\n",
    "    \n",
    "    def begin_epoch(self):\n",
    "        self.epoch_start_time = time.time()\n",
    "        self.epoch_count += 1\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        \n",
    "    def end_epoch(self):\n",
    "        epoch_duration = time.time() -self.epoch_start_time\n",
    "        run_duration = time.time() -self.run_start_time\n",
    "        \n",
    "        loss = self.epoch_loss / len(self.loader.dataset)\n",
    "        accuracy = self.epoch_num_correct/len(self.loader.dataset)\n",
    "        \n",
    "        self.tb.add_scalar('Loss' ,loss ,self.epoch_count)\n",
    "        self.tb.add_scalar('Accuracy' ,accuracy ,self.epoch_count)\n",
    "        \n",
    "        for name ,param in self.network.named_parameters():\n",
    "            self.tb.add_histogram(name ,param ,self.epoch_count)\n",
    "            self.tb.add_histogram(f'{name}.grad' ,param.grad ,self.epoch_count)\n",
    "            \n",
    "        results = OrderedDict()\n",
    "        results['run'] = self.run_count \n",
    "        results['epoch'] = self.epoch_count\n",
    "        results['loss'] = loss\n",
    "        results['accuracy'] = accuracy\n",
    "        results['epoch_duration'] = epoch_duration\n",
    "        results['run_duration'] = run_duration\n",
    "        \n",
    "        for k ,v in self.run_params._asdict().items():#_asdict is a method of namedtuple which convert it to a dict\n",
    "            results[k] = v #key-value pair of dict is populated with field-value pair of namedtuple\n",
    "        self.run_data.append(results)\n",
    "#         Syntax: dictionary.items()\n",
    "#         Parameters: This method takes no parameters.\n",
    "#         Returns: A view object that displays a list of a given dictionaryâ€™s (key, value) tuple pair.\n",
    "        \n",
    "        df = pd.DataFrame.from_dict(self.run_data ,orient ='columns')\n",
    "        \n",
    "        clear_output(wait = True)\n",
    "        display(df)\n",
    "    \n",
    "    def track_loss(self ,loss ,batch):\n",
    "        self.epoch_loss += loss.item() * batch[0].shape[0] #batch unpacks to images and labels now batch[0] == images of shape \n",
    "                                                           #batch[0].shape==[batch_size,channels,height,width]\n",
    "                                                           #batch[0].shape[0] == batch_size\n",
    "    \n",
    "    def track_num_correct(self, preds, labels):\n",
    "        self.epoch_num_correct += self.get_num_correct(preds, labels)\n",
    "    \n",
    "    def get_num_correct(self, preds, labels):\n",
    "        return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "    \n",
    "    def save(self, fileName):\n",
    "        pd.DataFrame.from_dict(self.run_data, orient='columns').to_csv(f'{fileName}.csv')\n",
    "        with open(f'{fileName}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.run_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "615db968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('run', 1),\n",
       "              ('epoch', 1),\n",
       "              ('loss', 1.0608767877022425),\n",
       "              ('accuracy', 0.5936166666666667),\n",
       "              ('epoch_duration', 28.22715973854065),\n",
       "              ('run_duration', 30.030163526535034),\n",
       "              ('lr', 0.01),\n",
       "              ('batch_size', 1000),\n",
       "              ('shuffle', True)]),\n",
       " OrderedDict([('run', 1),\n",
       "              ('epoch', 2),\n",
       "              ('loss', 0.5743795787294705),\n",
       "              ('accuracy', 0.7748333333333334),\n",
       "              ('epoch_duration', 28.0795316696167),\n",
       "              ('run_duration', 58.33154487609863),\n",
       "              ('lr', 0.01),\n",
       "              ('batch_size', 1000),\n",
       "              ('shuffle', True)]),\n",
       " OrderedDict([('run', 1),\n",
       "              ('epoch', 3),\n",
       "              ('loss', 0.4824780349930127),\n",
       "              ('accuracy', 0.8188666666666666),\n",
       "              ('epoch_duration', 26.7427818775177),\n",
       "              ('run_duration', 85.26679873466492),\n",
       "              ('lr', 0.01),\n",
       "              ('batch_size', 1000),\n",
       "              ('shuffle', True)]),\n",
       " OrderedDict([('run', 1),\n",
       "              ('epoch', 4),\n",
       "              ('loss', 0.42691662112871803),\n",
       "              ('accuracy', 0.84085),\n",
       "              ('epoch_duration', 28.065804958343506),\n",
       "              ('run_duration', 113.5667622089386),\n",
       "              ('lr', 0.01),\n",
       "              ('batch_size', 1000),\n",
       "              ('shuffle', True)]),\n",
       " OrderedDict([('run', 1),\n",
       "              ('epoch', 5),\n",
       "              ('loss', 0.38093562722206115),\n",
       "              ('accuracy', 0.8595166666666667),\n",
       "              ('epoch_duration', 28.28162384033203),\n",
       "              ('run_duration', 142.0655481815338),\n",
       "              ('lr', 0.01),\n",
       "              ('batch_size', 1000),\n",
       "              ('shuffle', True)]),\n",
       " OrderedDict([('run', 2),\n",
       "              ('epoch', 1),\n",
       "              ('loss', 0.9660895188649495),\n",
       "              ('accuracy', 0.628),\n",
       "              ('epoch_duration', 27.558884143829346),\n",
       "              ('run_duration', 29.161914348602295),\n",
       "              ('lr', 0.01),\n",
       "              ('batch_size', 1000),\n",
       "              ('shuffle', False)]),\n",
       " OrderedDict([('run', 2),\n",
       "              ('epoch', 2),\n",
       "              ('loss', 0.5484391803542773),\n",
       "              ('accuracy', 0.7862),\n",
       "              ('epoch_duration', 27.644190073013306),\n",
       "              ('run_duration', 57.023847818374634),\n",
       "              ('lr', 0.01),\n",
       "              ('batch_size', 1000),\n",
       "              ('shuffle', False)]),\n",
       " OrderedDict([('run', 2),\n",
       "              ('epoch', 3),\n",
       "              ('loss', 0.4588266556461652),\n",
       "              ('accuracy', 0.8324833333333334),\n",
       "              ('epoch_duration', 28.215434551239014),\n",
       "              ('run_duration', 85.46202659606934),\n",
       "              ('lr', 0.01),\n",
       "              ('batch_size', 1000),\n",
       "              ('shuffle', False)]),\n",
       " OrderedDict([('run', 2),\n",
       "              ('epoch', 4),\n",
       "              ('loss', 0.4019626170396805),\n",
       "              ('accuracy', 0.8516666666666667),\n",
       "              ('epoch_duration', 27.706347465515137),\n",
       "              ('run_duration', 113.39240217208862),\n",
       "              ('lr', 0.01),\n",
       "              ('batch_size', 1000),\n",
       "              ('shuffle', False)]),\n",
       " OrderedDict([('run', 2),\n",
       "              ('epoch', 5),\n",
       "              ('loss', 0.36269277036190034),\n",
       "              ('accuracy', 0.8668666666666667),\n",
       "              ('epoch_duration', 28.581040382385254),\n",
       "              ('run_duration', 142.18403840065002),\n",
       "              ('lr', 0.01),\n",
       "              ('batch_size', 1000),\n",
       "              ('shuffle', False)]),\n",
       " OrderedDict([('run', 3),\n",
       "              ('epoch', 1),\n",
       "              ('loss', 1.1870692908763885),\n",
       "              ('accuracy', 0.5360166666666667),\n",
       "              ('epoch_duration', 27.6517333984375),\n",
       "              ('run_duration', 31.044456481933594),\n",
       "              ('lr', 0.01),\n",
       "              ('batch_size', 2000),\n",
       "              ('shuffle', True)]),\n",
       " OrderedDict([('run', 3),\n",
       "              ('epoch', 2),\n",
       "              ('loss', 0.6383012016614278),\n",
       "              ('accuracy', 0.7533833333333333),\n",
       "              ('epoch_duration', 26.882943630218506),\n",
       "              ('run_duration', 58.144712924957275),\n",
       "              ('lr', 0.01),\n",
       "              ('batch_size', 2000),\n",
       "              ('shuffle', True)]),\n",
       " OrderedDict([('run', 3),\n",
       "              ('epoch', 3),\n",
       "              ('loss', 0.5265509277582169),\n",
       "              ('accuracy', 0.8006666666666666),\n",
       "              ('epoch_duration', 26.210936546325684),\n",
       "              ('run_duration', 84.55008268356323),\n",
       "              ('lr', 0.01),\n",
       "              ('batch_size', 2000),\n",
       "              ('shuffle', True)]),\n",
       " OrderedDict([('run', 3),\n",
       "              ('epoch', 4),\n",
       "              ('loss', 0.4700181106726328),\n",
       "              ('accuracy', 0.8272666666666667),\n",
       "              ('epoch_duration', 27.36899423599243),\n",
       "              ('run_duration', 112.15499758720398),\n",
       "              ('lr', 0.01),\n",
       "              ('batch_size', 2000),\n",
       "              ('shuffle', True)]),\n",
       " OrderedDict([('run', 3),\n",
       "              ('epoch', 5),\n",
       "              ('loss', 0.427713014682134),\n",
       "              ('accuracy', 0.8443666666666667),\n",
       "              ('epoch_duration', 27.103096961975098),\n",
       "              ('run_duration', 139.47480821609497),\n",
       "              ('lr', 0.01),\n",
       "              ('batch_size', 2000),\n",
       "              ('shuffle', True)]),\n",
       " OrderedDict([('run', 4),\n",
       "              ('epoch', 1),\n",
       "              ('loss', 1.3698295732339223),\n",
       "              ('accuracy', 0.47275),\n",
       "              ('epoch_duration', 25.559162855148315),\n",
       "              ('run_duration', 28.98339557647705),\n",
       "              ('lr', 0.01),\n",
       "              ('batch_size', 2000),\n",
       "              ('shuffle', False)]),\n",
       " OrderedDict([('run', 4),\n",
       "              ('epoch', 2),\n",
       "              ('loss', 0.7217753112316132),\n",
       "              ('accuracy', 0.72005),\n",
       "              ('epoch_duration', 26.497591972351074),\n",
       "              ('run_duration', 55.693504333496094),\n",
       "              ('lr', 0.01),\n",
       "              ('batch_size', 2000),\n",
       "              ('shuffle', False)]),\n",
       " OrderedDict([('run', 4),\n",
       "              ('epoch', 3),\n",
       "              ('loss', 0.6099669575691223),\n",
       "              ('accuracy', 0.76305),\n",
       "              ('epoch_duration', 27.846189260482788),\n",
       "              ('run_duration', 83.78535985946655),\n",
       "              ('lr', 0.01),\n",
       "              ('batch_size', 2000),\n",
       "              ('shuffle', False)]),\n",
       " OrderedDict([('run', 4),\n",
       "              ('epoch', 4),\n",
       "              ('loss', 0.551997313896815),\n",
       "              ('accuracy', 0.7844666666666666),\n",
       "              ('epoch_duration', 26.696831941604614),\n",
       "              ('run_duration', 110.70156764984131),\n",
       "              ('lr', 0.01),\n",
       "              ('batch_size', 2000),\n",
       "              ('shuffle', False)]),\n",
       " OrderedDict([('run', 4),\n",
       "              ('epoch', 5),\n",
       "              ('loss', 0.5112354516983032),\n",
       "              ('accuracy', 0.806),\n",
       "              ('epoch_duration', 30.0604887008667),\n",
       "              ('run_duration', 140.97913670539856),\n",
       "              ('lr', 0.01),\n",
       "              ('batch_size', 2000),\n",
       "              ('shuffle', False)])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.run_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34f866ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class run_builder():\n",
    "    @staticmethod\n",
    "    def  get_runs(params):\n",
    "        run = namedtuple('Run' ,params.keys())\n",
    "        runs = []\n",
    "        for v in product(*params.values()):\n",
    "            runs.append(run(*v))\n",
    "        return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75a7939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have to perform ETL ie extracting the data from any source,transform the data in tensor or any other required form and then create a loader object.\n",
    "#torchvision.datasets.FashionMNIST code handels the loading and transform task and torch.utils.data.DataLoader handels tge loader object task.\n",
    "\n",
    "train_set=torchvision.datasets.FashionMNIST(root='./data/FashionMNIST',train=True,download=True,transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "#We can pass an entire list(here we pass only one transformation i.e. transforms.ToTensor) of transformations to our data(batch of images here) which would be performed one after the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29481146",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network,self).__init__()\n",
    "        self.conv1=nn.Conv2d(in_channels=1,out_channels=6,kernel_size=5)\n",
    "        self.conv2=nn.Conv2d(in_channels=6,out_channels=12,kernel_size=5)\n",
    "        self.fc1=nn.Linear(in_features=12*4*4,out_features=120)\n",
    "        self.fc2=nn.Linear(in_features=120,out_features=60)\n",
    "        self.out=nn.Linear(in_features=60,out_features=10)\n",
    "        \n",
    "    def forward(self,t):\n",
    "        t=F.relu(self.conv1(t))\n",
    "        t=F.max_pool2d(t,kernel_size=2,stride=2)\n",
    "        \n",
    "        t=F.relu(self.conv2(t))\n",
    "        t=F.max_pool2d(t,kernel_size=2,stride=2)\n",
    "        \n",
    "        t=F.relu(self.fc1(t.reshape(-1,12*4*4)))\n",
    "        t=F.relu(self.fc2(t))\n",
    "        t=self.out(t)\n",
    "        \n",
    "        return t\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b446af90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>epoch_duration</th>\n",
       "      <th>run_duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>shuffle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.060877</td>\n",
       "      <td>0.593617</td>\n",
       "      <td>28.227160</td>\n",
       "      <td>30.030164</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.574380</td>\n",
       "      <td>0.774833</td>\n",
       "      <td>28.079532</td>\n",
       "      <td>58.331545</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.482478</td>\n",
       "      <td>0.818867</td>\n",
       "      <td>26.742782</td>\n",
       "      <td>85.266799</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.426917</td>\n",
       "      <td>0.840850</td>\n",
       "      <td>28.065805</td>\n",
       "      <td>113.566762</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.380936</td>\n",
       "      <td>0.859517</td>\n",
       "      <td>28.281624</td>\n",
       "      <td>142.065548</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.966090</td>\n",
       "      <td>0.628000</td>\n",
       "      <td>27.558884</td>\n",
       "      <td>29.161914</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.548439</td>\n",
       "      <td>0.786200</td>\n",
       "      <td>27.644190</td>\n",
       "      <td>57.023848</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.458827</td>\n",
       "      <td>0.832483</td>\n",
       "      <td>28.215435</td>\n",
       "      <td>85.462027</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.401963</td>\n",
       "      <td>0.851667</td>\n",
       "      <td>27.706347</td>\n",
       "      <td>113.392402</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.362693</td>\n",
       "      <td>0.866867</td>\n",
       "      <td>28.581040</td>\n",
       "      <td>142.184038</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.187069</td>\n",
       "      <td>0.536017</td>\n",
       "      <td>27.651733</td>\n",
       "      <td>31.044456</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.638301</td>\n",
       "      <td>0.753383</td>\n",
       "      <td>26.882944</td>\n",
       "      <td>58.144713</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.526551</td>\n",
       "      <td>0.800667</td>\n",
       "      <td>26.210937</td>\n",
       "      <td>84.550083</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.470018</td>\n",
       "      <td>0.827267</td>\n",
       "      <td>27.368994</td>\n",
       "      <td>112.154998</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.427713</td>\n",
       "      <td>0.844367</td>\n",
       "      <td>27.103097</td>\n",
       "      <td>139.474808</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.369830</td>\n",
       "      <td>0.472750</td>\n",
       "      <td>25.559163</td>\n",
       "      <td>28.983396</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.721775</td>\n",
       "      <td>0.720050</td>\n",
       "      <td>26.497592</td>\n",
       "      <td>55.693504</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.609967</td>\n",
       "      <td>0.763050</td>\n",
       "      <td>27.846189</td>\n",
       "      <td>83.785360</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.551997</td>\n",
       "      <td>0.784467</td>\n",
       "      <td>26.696832</td>\n",
       "      <td>110.701568</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.511235</td>\n",
       "      <td>0.806000</td>\n",
       "      <td>30.060489</td>\n",
       "      <td>140.979137</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    run  epoch      loss  accuracy  epoch_duration  run_duration    lr  \\\n",
       "0     1      1  1.060877  0.593617       28.227160     30.030164  0.01   \n",
       "1     1      2  0.574380  0.774833       28.079532     58.331545  0.01   \n",
       "2     1      3  0.482478  0.818867       26.742782     85.266799  0.01   \n",
       "3     1      4  0.426917  0.840850       28.065805    113.566762  0.01   \n",
       "4     1      5  0.380936  0.859517       28.281624    142.065548  0.01   \n",
       "5     2      1  0.966090  0.628000       27.558884     29.161914  0.01   \n",
       "6     2      2  0.548439  0.786200       27.644190     57.023848  0.01   \n",
       "7     2      3  0.458827  0.832483       28.215435     85.462027  0.01   \n",
       "8     2      4  0.401963  0.851667       27.706347    113.392402  0.01   \n",
       "9     2      5  0.362693  0.866867       28.581040    142.184038  0.01   \n",
       "10    3      1  1.187069  0.536017       27.651733     31.044456  0.01   \n",
       "11    3      2  0.638301  0.753383       26.882944     58.144713  0.01   \n",
       "12    3      3  0.526551  0.800667       26.210937     84.550083  0.01   \n",
       "13    3      4  0.470018  0.827267       27.368994    112.154998  0.01   \n",
       "14    3      5  0.427713  0.844367       27.103097    139.474808  0.01   \n",
       "15    4      1  1.369830  0.472750       25.559163     28.983396  0.01   \n",
       "16    4      2  0.721775  0.720050       26.497592     55.693504  0.01   \n",
       "17    4      3  0.609967  0.763050       27.846189     83.785360  0.01   \n",
       "18    4      4  0.551997  0.784467       26.696832    110.701568  0.01   \n",
       "19    4      5  0.511235  0.806000       30.060489    140.979137  0.01   \n",
       "\n",
       "    batch_size  shuffle  \n",
       "0         1000     True  \n",
       "1         1000     True  \n",
       "2         1000     True  \n",
       "3         1000     True  \n",
       "4         1000     True  \n",
       "5         1000    False  \n",
       "6         1000    False  \n",
       "7         1000    False  \n",
       "8         1000    False  \n",
       "9         1000    False  \n",
       "10        2000     True  \n",
       "11        2000     True  \n",
       "12        2000     True  \n",
       "13        2000     True  \n",
       "14        2000     True  \n",
       "15        2000    False  \n",
       "16        2000    False  \n",
       "17        2000    False  \n",
       "18        2000    False  \n",
       "19        2000    False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = OrderedDict(lr = [0.01] ,batch_size = [1000 ,2000] ,shuffle = [True ,False])\n",
    "\n",
    "m = RunManager()\n",
    "\n",
    "for run in run_builder().get_runs(params):\n",
    "    \n",
    "    network = Network()\n",
    "    loader = DataLoader(train_set ,batch_size = run.batch_size ,shuffle = run.shuffle)\n",
    "    optimizer = optim.Adam(network.parameters() ,lr = run.lr)\n",
    "    \n",
    "    m.begin_run(run ,network ,loader)\n",
    "    \n",
    "    for epoch in range(5):\n",
    "        m.begin_epoch()\n",
    "        for batch in loader:\n",
    "            images ,labels = batch\n",
    "            preds = network(images)\n",
    "            loss = F.cross_entropy(preds ,labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            m.track_loss(loss ,batch)\n",
    "            m.track_num_correct(preds ,labels)\n",
    "        m.end_epoch()\n",
    "    m.end_run()\n",
    "    \n",
    "m.save('results')\n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "# hyper_parameter = dict( batch_size = [10 ,100 ,1000] ,lr = [0.01 ,0.001] ,shuffle = [True ,False])\n",
    "# params_values = [v for v in hyper_parameter.values()]\n",
    "\n",
    "# for batch_size ,lr ,shuffle in product(*params_values):\n",
    "\n",
    "#     network = Network()\n",
    "#     train_loader= torch.utils.data.DataLoader(train_set,batch_size=batch_size ,shuffle=shuffle)\n",
    "#     optimizer=optim.Adam(network.parameters(), lr=lr)\n",
    "    \n",
    "#     images, labels = next(iter(train_loader))\n",
    "#     grid = torchvision.utils.make_grid(images)\n",
    "    \n",
    "#     comment=f' batch_size={batch_size} lr={lr} shuffle = {shuffle}'\n",
    "#     tb = SummaryWriter(comment = comment)\n",
    "#     tb.add_image('images', grid)\n",
    "#     tb.add_graph(network, images)\n",
    "\n",
    "    \n",
    "#     for epoch in range(10):\n",
    "#         total_loss = 0\n",
    "#         total_correct = 0\n",
    "\n",
    "\n",
    "#         for images ,labels in train_loader:\n",
    "\n",
    "#             preds = network(images) #pass batch\n",
    "#             loss = F.cross_entropy(preds ,labels) #calculate loss\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward() #calculate gradient\n",
    "#             optimizer.step() #update weights\n",
    "\n",
    "#             total_loss += loss.item() * batch_size #batch size is multiplied to account for the different size batches incase we want to compare the performance with different batch size\n",
    "#             total_correct += get_correct_preds(preds ,labels)\n",
    "#         tb.add_scalar('loss',total_loss,epoch)\n",
    "#         tb.add_scalar('number of correct preds',total_correct,epoch)\n",
    "#         tb.add_scalar('Accuracy',total_correct/len(train_set),epoch)\n",
    "\n",
    "#         for name,weight in network.named_parameters():\n",
    "#             tb.add_histogram(name,weight,epoch)\n",
    "#             tb.add_histogram(name,weight.grad,epoch)\n",
    "\n",
    "\n",
    "#         print(\"epoch :\",epoch ,'total_loss :',total_loss,'total_correct :',total_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "63b76ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_all_pred(loader,model):\n",
    "    all_preds = torch.tensor([])\n",
    "    for images ,labels in loader:\n",
    "        preds = model(images)\n",
    "        all_preds = torch.cat((all_preds,preds),dim=0)\n",
    "    return all_preds\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "c76161e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(train_set ,batch_size = 10000 )\n",
    "all_preds = get_all_pred(loader ,network )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "eab4ab08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 10])"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "b9ee255e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 6],\n",
      "        [3, 5],\n",
      "        [4, 8]])\n",
      "tensor([[1, 2, 3, 5],\n",
      "        [3, 6, 4, 8]])\n"
     ]
    }
   ],
   "source": [
    "t1=torch.tensor([[1,2],[3,6]])\n",
    "t2=torch.tensor([[3,5],[4,8]])  #this is an example to illustrate the concatenation operation in general\n",
    "t3=torch.cat((t1,t2),dim=0)\n",
    "print(t3)\n",
    "t1=torch.tensor([[1,2],[3,6]])\n",
    "t2=torch.tensor([[3,5],[4,8]])  #this is an example to illustrate the concatenation operation in general\n",
    "t4=torch.cat((t1,t2),dim=1)\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "c334f40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total correct : 53018\n",
      "prediction accuracy : 0.8836333333333334\n"
     ]
    }
   ],
   "source": [
    "total_correct = get_correct_preds(all_preds ,train_set.targets)\n",
    "\n",
    "print('total correct :',total_correct)\n",
    "print('prediction accuracy :',total_correct/60000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "dd9bc162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 0, 0,  ..., 3, 0, 5])\n",
      "tensor([9, 0, 0,  ..., 3, 0, 5])\n"
     ]
    }
   ],
   "source": [
    "#creation of the confusion matrix\n",
    "print(all_preds.argmax(dim=1))\n",
    "print(train_set.targets)\n",
    "stacked=torch.stack((all_preds.argmax(dim=1),train_set.targets), dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "c04264a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9, 9],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        ...,\n",
       "        [3, 3],\n",
       "        [0, 0],\n",
       "        [5, 5]])"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "e99e858c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmt = torch.zeros((10,10),dtype = torch.int64)\n",
    "cmt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "91b7e975",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in stacked:\n",
    "    (i ,j) = k.tolist()\n",
    "    cmt[i][j] = cmt[i][j] + 1     #cmt is used to indicate the confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "7e8463cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10622,    32,   106,   418,    12,     4,  2232,     0,    18,     2],\n",
       "        [    6, 11558,     0,    20,     8,     2,     8,     0,     2,     0],\n",
       "        [  224,    12, 10354,   102,  1168,     0,  1290,     0,   108,     0],\n",
       "        [  230,   292,    58, 10682,   262,     4,   194,     0,    44,     0],\n",
       "        [   22,    22,   796,   512,  9408,     0,   718,     0,    26,     0],\n",
       "        [    0,     2,     2,     0,     0, 11352,     2,    86,    22,    30],\n",
       "        [  788,    56,   614,   242,  1040,     6,  7392,     0,    84,     2],\n",
       "        [    0,     0,     2,     0,     0,   336,     0, 11236,    24,   188],\n",
       "        [  106,    26,    68,    22,    98,    44,   164,    12, 11670,    16],\n",
       "        [    2,     0,     0,     2,     4,   252,     0,   666,     2, 11762]])"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "986cf831",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5311,    3,  112,  115,   11,    0,  394,    0,   53,    1],\n",
       "       [  16, 5779,    6,  146,   11,    1,   28,    0,   13,    0],\n",
       "       [  53,    0, 5177,   29,  398,    1,  307,    1,   34,    0],\n",
       "       [ 209,   10,   51, 5341,  256,    0,  121,    0,   11,    1],\n",
       "       [   6,    4,  584,  131, 4704,    0,  520,    0,   49,    2],\n",
       "       [   2,    1,    0,    2,    0, 5676,    3,  168,   22,  126],\n",
       "       [1116,    4,  645,   97,  359,    1, 3696,    0,   82,    0],\n",
       "       [   0,    0,    0,    0,    0,   43,    0, 5618,    6,  333],\n",
       "       [   9,    1,   54,   22,   13,   11,   42,   12, 5835,    1],\n",
       "       [   1,    0,    0,    0,    0,   15,    1,   94,    8, 5881]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmt=confusion_matrix(train_set.targets,all_preds.argmax(dim=1))\n",
    "cmt #this is another way of plotting confusion matrix using the sklearn.metrics.confusion_matrix package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "ea0ca32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([[10, 100, 1000], [0.01, 0.001], [True, False]])"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_parameter = dict( batch_size = [10 ,100 ,1000] ,lr = [0.01 ,0.001] ,shuffle = [True ,False])\n",
    "hyper_parameter.values()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
